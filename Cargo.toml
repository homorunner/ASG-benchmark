[package]
name = "boardgamebench"
version = "0.1.0"
edition = "2024"
description = "A benchmark for evaluating LLM performance on abstract board game puzzles"

[lib]
name = "boardgamebench"
path = "src/lib.rs"

[dependencies]
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
anyhow = "1.0"
thiserror = "1.0"
chrono = { version = "0.4", features = ["serde"] }
openai-api-rs = "0.1"
clap = { version = "4.0", features = ["derive"] }
tokio = { version = "1.0", features = ["full"] }
dotenvy = "0.15.7"
shakmaty = "0.29.3"
regex = "1.11.3"
rand = "0.9.2"

[dev-dependencies]
criterion = "0.5"

[[bin]]
name = "bench"
path = "src/benchmark/main.rs"

[[bin]]
name = "generate"
path = "src/generate/main.rs"
